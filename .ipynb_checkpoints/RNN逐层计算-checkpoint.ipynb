{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b82adca-ebfa-484d-bda5-c91781eed398",
   "metadata": {},
   "source": [
    "<h2>循环神经网络</h2>\n",
    "<p>基础公式：</p>\n",
    "<p>$$\\mathbf{h_{t}} = f(\\mathbf{U}\\mathbf{h_{t-1}}+\\mathbf{W}\\mathbf{x_{t}}+\\mathbf{b})$$</p>\n",
    "<p>其中\\(f(*) \\)是非线性激活函数</p>\n",
    "<p><img src=\"https://pic1.zhimg.com/70/v2-397376bafce3f0c634f9f73161044c52_1440w.image?source=172ae18b&amp;biz_tag=Post\" alt=\"Pytorch实现RNN\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6ddd979-8897-42cc-9e68-d9acc6206359",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0: torch.Size([1, 1])\n",
      "tensor([[-0.0075]])\n",
      "weight_hh_l0: torch.Size([1, 1])\n",
      "tensor([[0.5364]])\n",
      "bias_ih_l0: torch.Size([1])\n",
      "tensor([-0.8230])\n",
      "bias_hh_l0: torch.Size([1])\n",
      "tensor([-0.7359])\n",
      "weight_ih_l1: torch.Size([1, 1])\n",
      "tensor([[-0.3852]])\n",
      "weight_hh_l1: torch.Size([1, 1])\n",
      "tensor([[0.2682]])\n",
      "bias_ih_l1: torch.Size([1])\n",
      "tensor([-0.0198])\n",
      "bias_hh_l1: torch.Size([1])\n",
      "tensor([0.7929])\n",
      "weight_ih_l2: torch.Size([1, 1])\n",
      "tensor([[-0.0887]])\n",
      "weight_hh_l2: torch.Size([1, 1])\n",
      "tensor([[0.2646]])\n",
      "bias_ih_l2: torch.Size([1])\n",
      "tensor([-0.3022])\n",
      "bias_hh_l2: torch.Size([1])\n",
      "tensor([-0.1966])\n",
      "hn:tensor([[[0.0000]],\n",
      "\n",
      "        [[1.0360]],\n",
      "\n",
      "        [[0.0000]]], grad_fn=<StackBackward0>)\n",
      "output:tensor([[[0.]],\n",
      "\n",
      "        [[0.]],\n",
      "\n",
      "        [[0.]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "# 创建一维数据和label，用pytorch创建一个最简单的RNN网络\n",
    "# 确保数据和标签的数据类型为 torch.float（即 torch.float32） RNN期待的输入数据通常是三维的，其形状为 (序列长度, 批量大小, 特征数量)。\n",
    "data = torch.tensor([[1.], [2.], [3.]], dtype=torch.float).reshape(3, 1, 1)\n",
    "label = torch.tensor([2., 3., 4.], dtype=torch.float)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 输入为1，中间隐藏层数量也为1, 堆叠层数为3 第一个参数是输入的特征数量，第二个参数是隐藏层的特征数量。你的数据形状需要与这些参数相匹配\n",
    "# 隐藏层的特征数量决定了网络的输出形状，在这个例子中，输出为简单的一维数字，因此隐藏层的形状为1\n",
    "rnn = nn.RNN(1, 1, num_layers=3, nonlinearity='relu')\n",
    "# 初始化隐藏状态 层数，批量大小，隐藏层形状\n",
    "h0 = torch.zeros(3, 1, 1)\n",
    "\n",
    "output, hn = rnn(data, h0)\n",
    "\n",
    "# 输出参数\n",
    "for name, param in rnn.named_parameters():\n",
    "    print(f\"{name}: {param.size()}\")\n",
    "    print(param.data)\n",
    "print(f\"hn:{hn}\")\n",
    "print(f\"output:{output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a543f-9159-418b-8832-dcb0638e8f36",
   "metadata": {},
   "source": [
    "<p>前向计算：</p>\n",
    "<p>$$ h_{0}=f(-0.0075*1+0.5364*0+(-0.8230)+(-0.7356))=f(-1.56)=0 $$</p>\n",
    "<p>$$ h_{1}=f(<span style=\"color: var(--jp-content-font-color1); font-family: var(--jp-code-font-family); font-size: var(--jp-code-font-size); background-color: #ffffff; white-space: pre-wrap;\">-0.3852</span>*2+<span style=\"color: var(--jp-content-font-color1); font-family: var(--jp-code-font-family); font-size: var(--jp-code-font-size); background-color: #ffffff; white-space: pre-wrap;\">0.2682</span>*h_{0}+(-<span style=\"color: var(--jp-content-font-color1); font-family: var(--jp-code-font-family); font-size: var(--jp-code-font-size); background-color: #ffffff; white-space: pre-wrap;\">0.0198</span>)+<span style=\"color: var(--jp-content-font-color1); font-family: var(--jp-code-font-family); font-size: var(--jp-code-font-size); background-color: #ffffff; white-space: pre-wrap;\">0.7929</span>)=f(0.0027)=0.0027 $$</p>\n",
    "<p>$$ h_{2}=f(<span style=\"background-color: #ffffff; color: var(--jp-content-font-color1); font-family: var(--jp-code-font-family); font-size: var(--jp-code-font-size); white-space: pre-wrap;\">-0.0887</span>*3+<span style=\"background-color: #ffffff; color: var(--jp-content-font-color1); font-family: var(--jp-code-font-family); font-size: var(--jp-code-font-size); white-space: pre-wrap;\">0.2646</span>*h_{1}+(<span style=\"background-color: #ffffff; color: var(--jp-content-font-color1); font-family: var(--jp-code-font-family); font-size: var(--jp-code-font-size); white-space: pre-wrap;\">-0.3022</span>)<span style=\"background-color: #ffffff; color: var(--jp-content-font-color1); font-family: var(--jp-code-font-family); font-size: var(--jp-code-font-size); white-space: pre-wrap;\">-0.1966</span>)=f(-0.7641)=0$$</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa2662-061a-4f09-abe8-3c907dd3b0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
